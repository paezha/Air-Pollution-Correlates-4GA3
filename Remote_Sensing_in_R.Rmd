---
title: Lecture 6 Remote Sensing
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align='center',
                      out.width = "0.8\\linewidth")
```

This notebook is for the class exercise or lesson on February 13th 2024 in the Advanced Remote Sensing Course. 
I will be taking notes here

This is the setup process for the project
```{r}
library(raster)
library(rgdal)
setwd("C:/Users/Owner/OneDrive/Documents/R/Remote Sensing/Lecture 6/R_data_lecture6")
```
#Loading and looking at the data
```{r}
setwd("C:/Users/Owner/OneDrive/Documents/R/Remote Sensing/Lecture 6/R_data_lecture6")
#load Landsat data for Las Vegas from 1985
ls85 <- brick("LasVegas1985LT05_CU_005011_19850806_20190604_C01_V01_SRB1_SRB7.dat")
# load Landsat data for Las Vegas from 2011
ls11 <- brick("LasVegas2011LT05_CU_005011_20110830_20190210_C01_V01_SRB1_SRB7.dat")
# A single band raster data (for example NIR Landsat image) can be read as a raster in R.
NIR85<-raster("LasVegasNIR_1985.tif")
print(ls85)
print(ls11)
print(NIR85)
```
Here we show how to look at the data in a bunch of ways.
```{r}
#coordinate reference system
crs(ls11)
#number of bands
nlayers(ls11)
# resolution x,y
res(NIR85)
# number of cells
ncell(ls11)
# dimensions
dim(NIR85)
# Do the bands have the same extent, number of rows, columns, projection, resolution and origin
compareRaster(ls11,ls85)
# summary statistics
summary(ls85)
```


This is how we stack two image files one on top of the other.
```{r}
s<-stack(ls85,NIR85)
print(s)
rm(s)
```
#Visualizing a single band and composite maps.

We can plot individual layers of a RasterStack of a multi-spectral image
```{r}
plot(NIR85)
# Plot band 2 (green) from teh 1985 image
plot(ls85[[2]])
```
To display 3-band color image, we use plotRGB. We have select the index of bands we want to render in the red, green and blue regions. For this Landsat image, r = 3 (red), g = 2(green), b = 1(blue) will plot the true color composite (vegetation in green, water blue etc). Selecting r = 4 (NIR), g = 3 (red), b = 2(green) will plot the false color composite (very popular in remote sensing with vegetation as red). You can find more about the visualization here.
```{r}
nf <- layout(matrix(c(1,0,2), 1, 3, byrow = TRUE), width = c(1,0.2,1), respect = TRUE)
plotRGB(ls85, r = 3, g = 2, b = 1, axes = TRUE, stretch = "lin", main = "Landsat True Color Composite")
plotRGB(ls85, r = 4, g = 3, b = 2, axes = TRUE, stretch = "lin", main = "Landsat False Color Composite")
```
Note: Always check for package documentation (help(plotRGB)) for other arguments that can be added (like scale) to improve or modify the image.

#Subset and rename spectral bands

```{r}
# select first 3 bands only
rsub <- subset(ls85,1:3)
#Number of bands in original and new data
nlayers(ls85)
nlayers(rsub)
#Read and set names of bands using the following:
names(ls85)
#set Names
names(ls85) <- c('blue','green','red','NIR','SWIR1','SWIR2')
names(ls11) <- c('blue','green','red','NIR','SWIR1','SWIR2')
#re-run code to check name change
names(ls85)
```
#Spatial subset/crop
Spatial subsetting can be used to limit analysis to a geographic subset of the image. Spatial subsets can be created with the crop function, using an extent object, or another spatial object from which an Extent can be extracted.

```{r}
#Using extent
extent(ls85)
# crop LANDSAT 85 image
e <- extent(-1710000,-1680000,1620000,1640000)
rr <- crop(ls85,e)
#Compare the 2 plots
plot(ls85[[2]])
plot(rr[[2]])
```
# Change spatial resolution or pixel size

Aggregate creates a lower resolution (larger cells) image from finer pixels. Aggregation groups rectangular areas to create larger cells. Reverse process is known as disaggreagte which creates higher resolution (smaller cells) from larger cells. These methods are particularly useful to compare (or analyze) data from different sources; for example, MODIS data 250 m with Landsat 30 m.

```{r}
ssa <- aggregate(rr,fact=9)
# Now plot the subsets side-by-side to compare the resolution and extent
nf <- layout(matrix(c(1,0,2), 1, 3, byrow = TRUE), width = c(1,0.2,1), respect = TRUE)
plotRGB(ssa, r = 4, g = 3, b = 2, axes = TRUE, stretch = "lin", main = "Landsat Subset")
plotRGB(ls85, r = 4, g = 3, b = 2, axes = TRUE, stretch = "lin", main = "Landsat original")
```
#Saving results to disk

At this stage we may want to save the raster to disk using the function writeRaster. Multiple file types are supported. We will use the commonly used GeoTiff format. While the layer order is preserved, layer names are unfortunately lost in the GeoTiff format.
```{r}
writeRaster(ssa, filename="cropped-landsat.tif", overwrite=TRUE)
```


Alternatively you can use the ‘raster-grd’ format. An advantage of this format is that it saves the layer names. The disadvantage of this format is that not many other programs can read the data, in contrast to the GeoTiff format.

#Relation between bands
A scatterplot matrix can be helpful in exploring relationships between spectral bands. This can be done with the pairs() function of the raster package. Plot of reflection in the red wavelength against reflection in the NIR wavelength.
```{r}
pairs(ls85[[4:3]], main = "Red versus NIR")
```
# Basic mathematical operations
Raster package supports many mathematical operations. Math operations are generally performed per pixel. First we will learn about basic arithmetic operations on bands. First example is a custom math function that calculates the Normalized Difference Vegetation Index (NDVI).

#Compute vegetation indices
Let’s define a general function for ratio based vegetation index. In the function below, img is a mutilayer Raster* object and i and k are the indices of the layers (spectral bands) used to compute the vegetation index.

```{r}
vi <- function(img, i, k) {
bi <- img[[i]]
bk <- img[[k]]
vi <- (bk-bi)/(bk+bi)
return(vi)
}
# For Landsat NIR = 4, red = 3.
ndvi <- vi(ls85, 3,4)
plot(ndvi, col = rev(terrain.colors(30)), main = 'NDVI')
#You can see the variation in greenness from the plot. An alternative way to accomplish this is like this
vi2 <- function(x, y) {
(x - y) / (x + y)
}
ndvi2 <- overlay(ls85[[4]], ls85[[3]], fun=vi2)
plot(ndvi2, col=rev(terrain.colors(10)), main=" NDVI")
```

#Histogram
We can explore the distribution of values contained within our raster using the hist() function which produces a histogram. Histograms are often useful in identifying outliers and bad data values in our raster data.

```{r}
# view histogram of NDVIdata
hist(ndvi,
main = "Distribution of NDVI values",
xlab = "NDVI",
ylab= "Frequency",
col = "wheat",
xlim = c(-0.6, 0.6),
breaks = 30,
xaxt = 'n')
# add axis labels
axis(side=1, at = seq(-0.6,0.6, 0.05), labels = seq(-0.6,0.6, 0.05))
```
# Thresholding
We can apply basic rules to get an estimate of spatial extent of different Earth surface features. Note that NDVI values range between -1 to +1. Higher values indicate more green cover. Pixels having NDVI values greater than 0.4 are definitely vegetation. Following operation masks all non vegetation pixels.
```{r}
veg <- calc(ndvi, function(x){x[x < 0.2] <- NA; return(x)})
plot(veg, main = 'Veg cover')
```


You can also create classes for different density of vegetation, 0 being no-vegetation.
```{r}
# -inf to 0.2 name it 0, 0.2 to 0.3 name it 1, etc
vegc <- reclassify(veg, c(-Inf,0.2,0, 0.2,0.3,1, 0.3,0.4,2, 0.4,0.5,3, 0.5, Inf, 4))
plot(vegc,col = rev(terrain.colors(4)), main = 'NDVI based thresholding')
```

You can plot land over original false colour landsat image to find out where the NDVI classes are
located.
```{r}
plotRGB(ls85, r=4, g=3, b=2, axes=TRUE, stretch="lin", main="Landsat False Color Composite")
plot(vegc, add=TRUE, legend=FALSE)
```

#Principal component analysis
The principal components (PC) transform (also known as the Karhunen-Loeve transform) is a spectral transformation which takes spectrally correlated image bands and generates uncorrelated bands. This process also helps to reduce the dimensionality and noise in the data. You can calculate the same number of principal components as the number of input bands. The first PC band explains the largest percentage of variance and other bands explain the variance in decreasing order. Last few bands appear noisy because they contain variance from the noise in original bands.

```{r}
set.seed(1) # sets the starting number used to generate a sequence of random numbers
sr <- sampleRandom(ls85, 10000) # select 10000 random pixels
plot(sr[,c(4,3)])
```

This plot is known as vegetation and soil-line plot (Same as the scatter plot in earlier section). You
can guess the directions of principal components.
```{r}
pca <- prcomp(sr, scale = TRUE)
pca
plot(pca)
pci <- predict(ls85, pca, index = 1:2)
spplot(pci, col.regions = rev(heat.colors(20)), main = list(label="First 2 principal components"))
```

#Image classification
We will explore two classification methods: unsupervised and supervised. Various unsupervised and supervised classification algorithms may be used. Different choice of classifier may produce different results. We will explore two k-means (unsupervised) and decision tree (supervised) algorithms.

#Unsupervised classification
In unsupervised classification, we don’t supply any training data. This particularly is useful when we don’t have prior knowledge of the study area. The algorithm groups pixels with similar spectral characteristics into unique clusters/classes/groups following some statistically determined conditions. You have to re-label and combine these spectral clusters into information classes (for e.g. land-use land-cover).We will perform unsupervised classification from the ls85 data.

```{r}
# convert the raster to vecor/matrix
nr <- getValues(ls85)
# We want to create 10 clusters, allow 500 iterations, start with 5 random sets using "Lloyd" method
nr.km <- kmeans(na.omit(nr), centers = 10, iter.max = 500, nstart = 3, algorithm="Lloyd")
# kmeans returns an object of class "kmeans"
str(nr.km)
```

kmeans returns an object with 9 elements. The length of the cluster element within nr.km is 2629200 which is the same as
length of number of cells that exist in a single layer. The cell values of nr.km$cluster range between 1 to 10 corresponding to the input number of cluster we provided in the kmeans function. nr.km$cluster indicates the cluster label for corresponding pixel. We need to convert the nr.km$cluster values back to RasterLayer of the same dimension as the ndvi.

```{r}
# Use the ndvi object to set the cluster values to a new raster
knr <- ndvi
knr[] <- nr.km$cluster
plot(knr, main = 'Unsupervised classification')
```

#Supervised classification
Here we explore supervised classification. Various supervised classification algorithms exist, and the choice of algorithm can affect the results. Here we explore two related algorithms (CART and RandomForest). In a supervised classification, we have prior knowledge about some of the land-use and land-cover types through a combination of fieldwork, interpretation of high resolution imagery and personal experience. Specific sites in the study area that represent homogeneous examples of these known land-cover types are identified. These areas are commonly referred to as training sites because the spectral properties of these sites are used to train the classification algorithm. The following example uses a Classification and Regression Trees (CART) classifier (Breiman et al. 1984)

We will perform the following steps:

  • Generate sample sites based on a reference raster
  • Extract cell values from Landsat data for the sample sites
  • Train the classifier using training samples
  • Classify the Landsat data using the trained model
  • Evaluate the accuracy of the model
  
#Reference data
  
The National Land Cover Database 2011 (NLCD 2011) is a land cover product for the USA. NLCD is a 30-m Landsat-based land cover database spanning 4 epochs (1992, 2001, 2006 and 2011).
NLCD 2011 is based primarily on a decision-tree classification of circa 2011 Landsat data.
You can find the class names in NCLD 2011 here https://www.mrlc.gov/data/legends/national-land-
cover-database-2011-nlcd2011-legend. It has two pairs of class values and names that correspond to the
levels of land use and land cover classification system. These levels usually represent the level of
complexity, level I being the simplest with broad land use land cover categories. Read this report by
Anderson et al to learn more about this land use and land cover classification system.
```{r}
setwd("C:/Users/Owner/OneDrive/Documents/R/Remote Sensing/Lecture 6/R_data_lecture6")
nlcd <- brick('nlcd-L1.tif')
names(nlcd) <- c("nlcd2001", "nlcd2011") #name the two raster layers
# The class names and colors for plotting
nlcdclass <- c("Water", "Developed", "Barren", "Forest", "Shrubland", "Herbaceous",
"Planted/Cultivated", "Wetlands")
classdf <- data.frame(classvalue1 = c(1,2,3,4,5,7,8,9), classnames1 = nlcdclass)
# Hex codes of colors
classcolor <- c("#5475A8", "#B50000", "#D2CDC0", "#38814E", "#AF963C", "#D1D182",
"#FBF65D", "#C8E6F8")
# Now we ratify (RAT = "Raster Attribute Table") the ncld2011 (define RasterLayer as a categorical variable).
# This is helpful for plotting.
nlcd2011 <- nlcd[[2]]
nlcd2011 <- ratify(nlcd2011)
rat <- levels(nlcd2011)[[1]]
rat$landcover <- nlcdclass
levels(nlcd2011) <- rat
```
We did a lot of things here (read more about ratify). Note There is no class with value 6.

#Generate smaple sites
As we discussed in the class, training and/or validation data can come from a variety of sources. In this example we will generate the training and validation sample sites using the NLCD reference RasterLayer. Alternatively, you can use predefined sites that you may have collected from other sources. We will generate the sample sites following a stratified random sampling to ensure samples from each LULC class.

```{r}
# Load the training sites locations
# Set the random number generator to reproduce the results
set.seed(99)
# Sampling
samp2011 <- sampleStratified(nlcd2011, size = 200, na.rm = TRUE, sp = TRUE)
samp2011
# Number of samples in each class
table(samp2011$nlcd2011)
```

You can see there are two variables in samp2011. The cell column contains cell numbers of nlcd2011 sampled. nlcd2011 column contains the class values (1-9). We will drop the cell column later.

Here nlcd has integer values between 1-9. You will often find classnames are provided as string labels (e.g. water, crop, vegetation). You will need to ‘relabel’ class names to integer or factors if only string labels are supplied before using them as response variable in the classification. There are several approaches that could be used to convert these classes to integer codes. We can make a function that will reclassify the character strings representing land cover classes into integers based on the existing factor levels.

Let’s plot the training sites over the nlcd2011 RasterLayer to visualize the distribution of sampling locations.
```{r}
library(rasterVis) #install the package if it is not available
```
rasterVis offers more advanced (trellis/lattice) plotting of Raster* objects. Please install the package
if it is not available for your machine. install.packages("rasterVis ")

```{r}
plt <- levelplot(nlcd2011, col.regions = classcolor, main = 'Distribution of Training Sites')
print(plt + layer(sp.points(samp2011, pch = 3, cex = 0.5, col = 1)))
```

#Extract values for sites

```{r}
setwd("C:/Users/Owner/OneDrive/Documents/R/Remote Sensing/Lecture 6/R_data_lecture6")
landsat5 <- stack('centralvalley-2011LT5.tif')
names(landsat5) <- c('blue', 'green', 'red', 'NIR', 'SWIR1', 'SWIR2')
```
Once we have the sites, we can extract the cell values from landsat5 RasterStack. These band values will be the predictor variables and “classvalues” from nlcd2011 will be the response variable.
```{r}
# Extract the layer values for the locations
sampvals <- extract(landsat5, samp2011, df = TRUE)
# samples no longer have the spatial information. To keep the spatial information you use `sp=TRUE` argument in
#the `extract` function.
# drop the ID column
sampvals <- sampvals[, -1]
# combine the class information with extracted values
sampdata <- data.frame(classvalue = samp2011@data$nlcd2011, sampvals)
```

#Train the classifier
Now we will train the classification algorithm using training2011 dataset.
```{r}
library(rpart)
```
```{r}
# Train the model
cart <- rpart(as.factor(classvalue)~., data=sampdata, method = 'class', minsplit = 5)
# print(model.class)
# Plot the trained classification tree
plot(cart, uniform=TRUE, main="Classification Tree")
text(cart, cex = 0.8)
```
In the classification tree plot classvalues are printed at the leaf nodes. You can find the corresponding land use land cover names from the classdf data.frame.

See ?rpart.control to set different parameters for building the model.

You can print/plot more about the cart model created in the previous example. E.g. you can use plotcp(cart) to learn about the cost-complexity (cp argument in rpart)

#Classify
Now we have our trained classification model (cart), we can use it to make predictions, that is, to classify all cells in the landsat5 RasterStack.

Important The names in the Raster object to be classified should exactly match those expected by the model. This will be the case if the same Raster object was used (via extract) to obtain the values to fit the model.

```{r}
# Now predict the subset data based on the model; prediction for entire area takes longer time
pr2011 <- predict(landsat5, cart, type='class')
pr2011
#Now plot the classification result using rasterVis. We will set the classnames for the classvalues.
pr2011 <- ratify(pr2011)
rat <- levels(pr2011)[[1]]
rat$legend <- classdf$classnames
levels(pr2011) <- rat
levelplot(pr2011, maxpixels = 1e6,
col.regions = classcolor,
scales=list(draw=FALSE),
main = "Decision Tree classification of Landsat 5")

```

#Model Evaluation
Now let’s assess the accuracy of the model to get an idea of how accurate the classified map might be. Two widely used measures in remote sensing are “overall accuracy” and “kappa”. You can perform the accuracy assessment using the independent samples (validation2011).

To evaluate any model, you can use k-fold cross-validation. In this technique the data used to fit the model is split into k groups (typically 5 groups). In turn, one of the groups will be used for model testing, while the rest of the data is used for model training (fitting).

```{r}
install.packages("dismo")
library(dismo) #install the package
```


```{r}
set.seed(99)
j <- kfold(sampdata, k = 5, by=sampdata$classvalue)
table(j)

#Now we train and test the model five times, each time computing a confusion matrix that we store in a list.
x <- list()
for (k in 1:5) {
train <- sampdata[j!= k, ]
test <- sampdata[j == k, ]
cart <- rpart(as.factor(classvalue)~., data=train, method = 'class', minsplit = 5)
pclass <- predict(cart, test, type='class')
# create a data.frame using the reference and prediction
x[[k]] <- cbind(test$classvalue, as.integer(pclass))
}
#Now combine the five list elements into a single data.frame, using do.call and compute a confusion matrix.
y <- do.call(rbind, x)
y <- data.frame(y)
colnames(y) <- c('observed', 'predicted')
conmat <- table(y)
# change the name of the classes
colnames(conmat) <- classdf$classnames
rownames(conmat) <- classdf$classnames
conmat
#Compute the overall accuracy and the “Kappa” statistic.
# number of cases
n <- sum(conmat)
n
# number of correctly classified cases per class
diag <- diag(conmat)
# Overall Accuracy
OA <- sum(diag) / n
OA
#Kappa
# observed (true) cases per class
rowsums <- apply(conmat, 1, sum)
p <- rowsums / n
# predicted cases per class
colsums <- apply(conmat, 2, sum)
q <- colsums / n
expAccuracy <- sum(p*q)
kappa <- (OA - expAccuracy) / (1 - expAccuracy)
kappa
#Producer and user accuracy
# Producer accuracy
PA <- diag / colsums
# User accuracy
UA <- diag / rowsums
outAcc <- data.frame(producerAccuracy = PA, userAccuracy = UA)
outAcc

```




