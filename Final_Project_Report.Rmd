---
title: "Some Random Title Here"
#subtitle: "A subtitle"
thanks: "Paper submitted to complete the requirements of ENVSOCTY 4GA3 Applied Spatial Statistics; with additional edits by Antonio Paez for this version."
author:
- name: Farah Chin
  student_number: 400229991
- name: Talat Hakim
  student_number: 400315290
- name: Nathan Nadeau
  student_number: 400342430
- name: Cindia Dao-Vu
  student_number: 400319161
- name: Ifra Awan
  student_number: 400261667 
- name: Oliver
  student_number: 
subject: "ENVSOCTY 4GA3"
abstract: "abstract goes here; some extra spiel added here"
keywords: "opioids, education, income, spatial analysis"
date: "4/6/2020"
output:
  pdf_document:
    # The project-template-default.tex file was minimally adapted from Steven V. Miller's template for academic manuscripts. See:
    # http://svmiller.com/blog/2016/02/svm-r-markdown-manuscript/
    # https://github.com/svmiller/svm-r-markdown-templates/blob/master/svm-latex-ms.tex
    template: project-template-default.tex
bibliography: [bibliography.bib, packages.bib]
always_allow_html: true
---

# Introduction

Words go here

More text for introduction
Add more words. For a review of land use regression models see @hoek2008review.

```{r}
rm(list = ls())
```

# Data

```{r message = FALSE, warning = FALSE}
# Load libraries for interpolation (might not need all of them)
library(deldir) # Delaunay Triangulation and Dirichlet (Voronoi) Tessellation
library(isdas) # Companion Package for Book An Introduction to Spatial Data Analysis and Statistics
#library(plotly) # Create Interactive Web Graphics via 'plotly.js'
library(gstat) # for IDW
library(spatstat) # Spatial Point Pattern Analysis, Model-Fitting, Simulation, Tests
library(spatstat.explore) # Exploratory Data Analysis for the 'spatstat' Family
library(spdep) # Spatial Dependence: Weighting Schemes, Statistics
library(tidyverse) # Easily Install and Load the 'Tidyverse'
library(sf)
library(cancensus) #retrieve Canadian Census Data
library(geojsonsf)

library(stars)
library(readxl) # for importing data from excel
library(Metrics) # for MSE function
library(patchwork) # for plotting multiple ggplots together
library(stringr)
```

```{r}
# Load the air quality data
 
AQ_data <- read_excel('data/Air_Quality_Data.xlsx')
colnames(AQ_data)[4] <- c("P")
# 
# AQ_data <- mutate(AQ_data,
#                   X3 = X^3, X2Y = X^2 * Y, X2 = X^2,
#                   XY = X * Y,
#                   Y2 = Y^2, XY2 = X * Y^2, Y3 = Y^3)
```

```{r}
summary(AQ_data)
```

```{r}
AQ_data.sf <- AQ_data |> 
  st_as_sf(coords = c("Lon", "Lat"), 
           remove = "FALSE") # Keep X and Y columns
```

```{r}
# function to determine the mean and sd of the prediction variance obtained with different kriging parameters
# observations: sf object containing the points to be interpolated (in this case the air pollution readings)
# polynomial terms need to have already been calculated
# targets: points that are being interpolated to (in this case the centroids)
# vgm_model: model of theoretical variogram (string)
# trend: what to use for the trend surface (can be Linear, Quadratic, Cubic, or None)
krig_pred_var <- function(observations, targets, vgm_model, trend = "None"){
  
  if(trend == "Linear"){
    trend_model <- P ~ X + Y
  } else if (trend == "Quadratic") {
    trend_model <- P ~ X2 + X + XY + Y + Y2
  } else if (trend == "Cubic") {
    trend_model <- P ~ X3 + X2Y + X2 + X + XY + Y + Y2 + XY2 + Y3
  } else {
    trend_model <- P ~ 1
  }
  
  variogram_v <- variogram(trend_model, 
                           data = observations)
  
  variogram_v.t <- fit.variogram(variogram_v, model = vgm(vgm_model))
  
  V.kriged <- krige(trend_model,
                    observations, 
                    targets, 
                    variogram_v.t)
  krig.list <- list(V.kriged, mean(V.kriged$var1.var), sd(V.kriged$var1.var))
  names(krig.list) <- c("Krig.output", "variance.mean", "variance.sd")
  return(krig.list)
}
```

```{r}
# Making air quality variogram
variogram_v <- variogram(P ~ 1, 
                           data = AQ_data.sf)

# Create best-fitting theoretical curve
variogram_v.t <- fit.variogram(variogram_v, model = vgm("Exp", "Sph", "Gau"))
variogram_v.t

gamma.t <- variogramLine(variogram_v.t, maxdist = 0.5)

# Plot semivariogram with fitted line
ggplot(data = variogram_v, 
       aes(x = dist,
           y = gamma)) + 
  geom_point() + 
  # Add labels to indicate the number of pairs of observations used
  # in the calculation of each point in the variogram
  geom_text(aes(label = np), 
            nudge_y = 10) +
  # Add theoretical semivariogram
  geom_line(data = gamma.t, 
            aes(x = dist, 
                y = gamma)) + 
  # Add labels to axes 
  xlab("Distance") + 
  ylab("Semivariance") 
```


## Toronto Census Data 

Go to https://mountainmath.github.io/cancensus/index.html and follow instructions for setting up CensusMapping account and generating API key to retrieve data.

More info: https://mountainmath.github.io/cancensus/articles/cancensus.html

Set your cache to the data folder:
```{r}
cancensus::set_cancensus_cache_path(paste0(getwd(), "/data"),install = TRUE, overwrite = TRUE)
```


```{r}
#Getting median household income from cancensus:

# census tract level (Toronto CSD)
# torontoCTs.demographics.sf <- get_census(dataset='CA21', regions=list(CSD="3520005"),
#                          vectors=c("median_hh_income"="v_CA21_906",
#                                    "population_density" = "v_CA21_6",
#                                    "median_age" = "v_CA21_389",
#                                    "public_transit" = "v_CA21_7644",
#                                    "automobile" = "v_CA21_7635",
#                                    "walking" = "v_CA21_7647",
#                                    "cycling" = "v_CA21_7650"), 
#                          level='CT', quiet = TRUE, 
#                          geo_format = 'sf', labels = 'short')

# dissemination area level (Toronto CSD)
torontoDAs.demographics.sf <- get_census(dataset='CA21', regions=list(CSD="3520005"),
                         vectors=c("median_hh_income"="v_CA21_906",
                                   "pop21" = "v_CA21_1",
                                   "population_density" = "v_CA21_6",
                                   "median_age" = "v_CA21_389",
                                   "public_transit" = "v_CA21_7644",
                                   "automobile" = "v_CA21_7635",
                                   "walking" = "v_CA21_7647",
                                   "cycling" = "v_CA21_7650",
                                   "minority_population" = "v_CA21_4875",
                                   "dwellings" = "v_CA21_434",
                                   "bachelors" = "v_CA21_5847"), 
                         level='DA', quiet = TRUE, 
                         geo_format = 'sf', labels = 'short')
```


```{r echo = FALSE}
#Projecting:
st_transform(torontoDAs.demographics.sf, 32617)
#st_transform(torontoDAs.demographics.sf, 4269)
#st_crs(torontoCTs.demographics.sf) <- st_crs(torontoDAs.demographics.sf)
st_crs(AQ_data.sf) <- st_crs(torontoDAs.demographics.sf)
```

```{r}
AQ_data.sf <- AQ_data.sf |>
  mutate(X = unlist(map(AQ_data.sf$geometry, 1)), 
         Y = unlist(map(AQ_data.sf$geometry, 2))) |>
  # Add polynomials
  mutate(X3 = X^3, X2Y = X^2 * Y, X2 = X^2,
         XY = X * Y, 
         Y2 = Y^2, XY2 = X * Y^2, Y3 = Y^3)
```


```{r}
ggplot(torontoDAs.demographics.sf) + geom_sf() + geom_sf(data = AQ_data.sf, aes(size = P))
```


```{r}
# generating centroids
torontoDAs.centroids <- st_centroid(torontoDAs.demographics.sf)
#torontoCTs.centroids <- st_centroid(torontoCTs.demographics.sf)
```

```{r}
# Extract coordinates as separate 'X' and 'Y' columns
torontoDAs.centroids <- torontoDAs.centroids |>
  mutate(X = unlist(map(torontoDAs.centroids$geometry, 1)), 
         Y = unlist(map(torontoDAs.centroids$geometry, 2))) |>
  # Add polynomials
  mutate(X3 = X^3, X2Y = X^2 * Y, X2 = X^2,
         XY = X * Y, 
         Y2 = Y^2, XY2 = X * Y^2, Y3 = Y^3)
```


```{r}
## IDW

to.bbox <- st_bbox(torontoDAs.demographics.sf)

# Get minimum and maximum values for aquifer data
min.X <- min(min(AQ_data$Lon), to.bbox$xmin)
min.Y <- min(min(AQ_data$Lat), to.bbox$ymin)
max.X <- max(max(AQ_data$Lon), to.bbox$xmax)
max.Y <- max(max(AQ_data$Lat), to.bbox$ymax)
x.range <- max.X - min.X
y.range <- max.Y - min.Y

# Define region of interest
AQ.bbox <- st_polygon(list(rbind(c(min.X, min.Y),
                                c(max.X, min.Y),
                                c(max.X, max.Y),
                                c(min.X, max.Y),
                                c(min.X, min.Y))))

AQ.owin <- as.owin(AQ.bbox)

# We can create a `ppp` object with the coordinates of the points
AQ_data.ppp <- as.ppp(X = AQ_data[,2:4], W = AQ.owin)
```

```{r}
summary(AQ_data.ppp)


plot(AQ_data.ppp)

```

Here we use Leave One Out cross validation to determine the optimal power: https://www.statology.org/leave-one-out-cross-validation/

See also:
https://rpubs.com/Dr_Gurpreet/interpolation_idw_R

```{r}
# CROSS VALIDATION

powers <- seq(0.001, 10, 0.01)
mse_result <- NULL
for(power in powers){
  P_idw <- idw(AQ_data.ppp, power=power, at="points")
  mse_result <- c(mse_result,
                  Metrics::mse(AQ_data.ppp$marks,P_idw))
}
optimal_power <- powers[which.min(mse_result)]
optimal_power
```

```{r}
P.idw_points <- idw(AQ_data.ppp, power = 0.471, at = "points")
P.idw_pixels <- idw(AQ_data.ppp, power = 0.471)
plot(P.idw_pixels, col=heat.colors(64))
#Metrics::mse(AQ_data.ppp$marks, z_p.idw1)
```

```{r}
# converting im object to a df
z.vec <- c(P.idw_pixels$v)
Y.vec <- rep(P.idw_pixels$yrow, 128)
X.vec <- rep(P.idw_pixels$xcol, each = 128)
P.idw.df <- data.frame("X" = X.vec, "Y" = Y.vec, "P" = z.vec)
P.idw.sf <- st_as_sf(P.idw.df, coords = c("X", "Y"))
st_crs(P.idw.sf) <- st_crs(torontoDAs.demographics.sf)


ggplot(P.idw.sf) + geom_sf(aes(colour = P)) + geom_sf(data = torontoDAs.demographics.sf)
```

```{r}
# use spatial join to add the PM25 value of the nearest pixel to each centroid
toDAs.idw <- st_join(torontoDAs.centroids, P.idw.sf, join = st_nearest_feature)

#ggplot(toDAs.idw) + geom_sf(aes(colour = P))

toDAs.idw.poly <- mutate(torontoDAs.demographics.sf, P = toDAs.idw$P)
toDAs.NAomit <- na.omit(toDAs.idw.poly)
ggplot(toDAs.idw.poly) + geom_sf(aes(fill = P), colour = NA) + labs(fill = "interpolated Particulate Matter value") + scale_fill_viridis_c(option = "magma")

# toCTs.idw <- na.omit(st_join(torontoCTs.demographics.sf, P.idw.sf, join = st_intersects))
# 
# ggplot(toCTs.idw) + geom_sf(aes(fill = P), colour = NA)
```


```{r message = FALSE}
# k.vals <- seq(1, 32)
# mse_result <- c()
# for(k in k.vals){
#   se.vec <- c()
#   for (i in 1:nrow(AQ_data.sf)){
#     train.sf <- AQ_data.sf[-i,]
#     test.sf <- AQ_data.sf[i, -4]
#     kpoint.k <- kpointmean(source_xy = train.sf,
#                        target_xy = test.sf,
#                        z = P,
#                        k = k)
# 
#     se.vec <- c(se.vec, (AQ_data.sf[i,]$P - kpoint.k$z)^2)
# 
#   }
#   mse <- mean(se.vec)
#   mse_result <- c(mse_result, mse)
# }
# optimal_k <- k.vals[which.min(mse_result)]
# optimal_k
```

```{r}

chloropleth.plot <- function(var, var.name){
  ggplot(data = toDAs.idw.poly) +
  geom_sf(aes(fill = var), colour = NA) + 
    scale_fill_viridis_c(option = "magma") + labs(title = str_wrap(var.name, 30), fill = str_wrap(var.name, 30))
}
```

```{r}
pop_den.chl <- chloropleth.plot(toDAs.idw.poly$pop21/toDAs.idw.poly$`Area (sq km)`, "Population density")
minority.chl <- chloropleth.plot(toDAs.idw.poly$minority_population/toDAs.idw.poly$pop21, "Proportion visible minority")
med_inc.chl <- chloropleth.plot(toDAs.idw.poly$median_hh_income, "Median household income")
med_age.chl <- chloropleth.plot(toDAs.idw.poly$median_age, "Median age")
automobile.chl <- chloropleth.plot(toDAs.idw.poly$automobile/toDAs.idw.poly$pop21, "Proportion commuting via automobile")
public_transit.chl <- chloropleth.plot(toDAs.idw.poly$public_transit/toDAs.idw.poly$pop21, "Proportion commuting via public transit")
walking.chl <- chloropleth.plot(toDAs.idw.poly$walking/toDAs.idw.poly$pop21, "Proportion commuting via walking")
cycling.chl <- chloropleth.plot(toDAs.idw.poly$cycling/toDAs.idw.poly$pop21, "Proportion commuting via cycling")
```

```{r}
(pop_den.chl | minority.chl) /
  (med_inc.chl | med_age.chl)

(automobile.chl | public_transit.chl) /
  (walking.chl | cycling.chl)
```


```{r}
torontoDAs.nb <- poly2nb(pl = toDAs.idw.poly, queen = TRUE)
torontoDAs.w <- nb2listw(torontoDAs.nb, zero.policy = TRUE)

torontoDAsna.nb <- poly2nb(pl = toDAs.NAomit, queen = TRUE)
torontoDAsna.w <- nb2listw(torontoDAsna.nb, zero.policy = TRUE)

# torontoCTs.nb <- poly2nb(pl = toCTs.idw)
# torontoCTs.w <- nb2listw(torontoCTs.nb)
# 
# torontoCTs.nb.k <- poly2nb(pl = toCT.kpoints)
# torontoCTs.k.w <- nb2listw(torontoCTs.nb.k, zero.policy = TRUE)
```



```{r}
moran.test.sum <- function(var){
  m <- moran.test(var, torontoDAsna.w)
  return(c("I" = m$estimate[1], "p.val" = m$p.value))
}
```
```{r}
moran.vec <- c("Population density", moran.test.sum(toDAs.NAomit$population_density),
               "Median household income", moran.test.sum(toDAs.NAomit$median_hh_income),
               "Median age", moran.test.sum(toDAs.NAomit$median_age),
               "Proportion visible minority", moran.test.sum(toDAs.NAomit$minority_population/toDAs.NAomit$pop21),
               "Proportion commuting via automobile", moran.test.sum(toDAs.NAomit$automobile/toDAs.NAomit$pop21),
               "Proportion commuting via public transportation", moran.test.sum(toDAs.NAomit$public_transit/toDAs.NAomit$pop21),
               "Proportion commuting via walking", moran.test.sum(toDAs.NAomit$walking/toDAs.NAomit$pop21),
               "Proportion commuting via cycling", moran.test.sum(toDAs.NAomit$cycling/toDAs.NAomit$pop21))

moran.mat <- matrix(moran.vec, ncol = 3, byrow = TRUE)

colnames(moran.mat) <- c("Variable", "Moran's Statistic (I)", "p-value")

moran.mat
```


```{r}

# Linear regression function
# Ask for variable
linreg <- function(var, name){
  # Complete linear regression and output summary
  PM25_var_corr <- lm(formula = P ~ var, data = toDAs.NAomit)
  #summary(PM25_var_corr)
  # Get variable name and title
  #title <- paste("PM25 &", name, "- Linear Regression")
  title <- paste(name, 
                 "; AR2 =", round(summary(PM25_var_corr)$r.squared, 2))
  # Plot results
  ggplot(data = toDAs.NAomit, aes(x = var, y = P)) + 
    geom_point() + 
    geom_abline(slope = PM25_var_corr$coefficients[2], 
                intercept = PM25_var_corr$coefficients[1], 
                colour = "Blue", 
                linewidth = 1) + 
    labs(title = str_wrap(title, 30)) +
    xlab(name) + ylab("Particulate Matter")
    
}
```

```{r}
Pop_den.lm <- linreg(toDAs.NAomit$population_density, "Population density")
med_inc.lm <- linreg(toDAs.NAomit$median_hh_income, "Median household income")
med_age.lm <- linreg(toDAs.NAomit$median_age, "Median Age")
automobile.lm <- linreg(toDAs.NAomit$automobile/toDAs.NAomit$pop21, "Proportion commuting via automobile")
public_transit.lm <- linreg(toDAs.NAomit$public_transit/toDAs.NAomit$pop21, "Proportion commuting via public transit")
walking.lm <- linreg(toDAs.NAomit$walking/toDAs.NAomit$pop21, "Proportion commuting via walking")
cycling.lm <- linreg(toDAs.NAomit$cycling/toDAs.NAomit$pop21, "Proportion commuting via cycling")
minority.lm <- linreg(toDAs.NAomit$minority_population/toDAs.NAomit$pop21, "Proportion of visible  minorities")
dwellings.lm <- linreg(toDAs.NAomit$dwellings/toDAs.NAomit$`Area (sq km)`, "Dwellings density")
bachelors.lm <- linreg(toDAs.NAomit$bachelors/toDAs.NAomit$pop21, "Proportion with at least a bachelor's")
```

```{r}
(Pop_den.lm | med_inc.lm) /
  (med_age.lm | minority.lm)

(automobile.lm | public_transit.lm) /
(walking.lm | cycling.lm )
```

```{r}
toDAs.NAomit$minority_proportion <- toDAs.NAomit$minority_population/toDAs.NAomit$pop21
toDAs.NAomit$automobile_prop <- toDAs.NAomit$automobile/toDAs.NAomit$pop21
toDAs.NAomit$public_tr_prop <- toDAs.NAomit$public_transit/toDAs.NAomit$pop21
toDAs.NAomit$walking_prop <- toDAs.NAomit$walking/toDAs.NAomit$pop21
toDAs.NAomit$cycling_prop <- toDAs.NAomit$cycling/toDAs.NAomit$pop21
```

```{r}
lm.all_vars <- lm(formula = P ~ population_density + 
                    minority_proportion + 
                    median_age +
                    median_hh_income +
                    automobile_prop +
                    public_tr_prop + 
                    walking_prop +
                    cycling_prop, 
                  data = toDAs.NAomit)
```

```{r}
summary(lm.all_vars)
```


Words

# Methods

Describing some methods.

# Results and discussion

<!-- I think it would be a good idea to have a section with the discussion of the findings -->

Here we will discuss the results of the analysis.

# References

